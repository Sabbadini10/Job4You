{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install required libraries\n",
        "!pip install --upgrade openai scikit-learn\n",
        "\n",
        "# STEP 2: Imports\n",
        "from openai import OpenAI\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# STEP 3: API key (keep this private)\n",
        "client = OpenAI(api_key=\"YOUR CHATGPT API KEY\")\n",
        "\n",
        "# STEP 4: Resume data and job description\n",
        "user_data = \"\"\"\n",
        "Name: YOUR FULL NAME\n",
        "Email: YOUR EMAIL\n",
        "Phone: YOUR PHONE NUMBER\n",
        "Location: YOUR LOCATION (optional)\n",
        "LinkedIn: YOUR LINKEDIN URL\n",
        "Website: YOUR PORTFOLIO URL\n",
        "\n",
        "Skills:\n",
        "- Python, JavaScript, TypeScript\n",
        "- Angular, Ionic, Firebase, HTML, CSS, Tailwind\n",
        "- GCP, GitHub Actions, Docker, REST APIs, CI/CD\n",
        "- OpenAI API, Gemini API, Prompt Engineering\n",
        "- Agile Methodology, Team Management\n",
        "\n",
        "Experience:\n",
        "YOUR EXPERIENCE at COMAPNY NAME (FROM ‚Äì TILL)\n",
        "- YOUR RESUME BULLET POINTS\n",
        "- Led a team of 12+ and exceeded targets by 15%\n",
        "- Improved operations using inventory systems and analytics\n",
        "\n",
        "FOR EXAMPLE Freelance Software Developer (2023 ‚Äì 2024)\n",
        "- Built ChattyAI and Job4You using AI + Firebase + Angular\n",
        "\n",
        "Projects:\n",
        "YOUR PROJECTS OR ANYTHING ELSE YOU WANT TO ADD\n",
        "FOR EXAMPLE Job4You  PROJECT URL (e.g. https://...)\n",
        "- YOUR BULLET POINTS\n",
        "- Resume generator and job automation platform\n",
        "\n",
        "Education:\n",
        "STUDYING/STUDIED, ORGANIZATION NAME (FROM ‚Äì TILL)\n",
        "\n",
        "Certifications:\n",
        "- YOUR CERTIFICATES OR ACHIEVEMENTS\n",
        "- AWS Certified Cloud Practitioner\n",
        "- Google Cloud Digital Leader\n",
        "\"\"\"\n",
        "\n",
        "job_description = \"\"\"\n",
        "PASTE YOUR JOB DESCRIPTION HERE\n",
        "\"\"\"\n",
        "\n",
        "# STEP 5: ATS score functions\n",
        "def calculate_ats_score(resume_text, job_description_text):\n",
        "    texts = [resume_text.lower(), job_description_text.lower()]\n",
        "    vect = CountVectorizer(stop_words='english').fit_transform(texts)\n",
        "    return round(cosine_similarity(vect[0:1], vect[1:2])[0][0] * 100, 2)\n",
        "\n",
        "def attach_ats_score_to_output(document_text, ats_score):\n",
        "    return f\"{document_text}\\n\\n---\\nüìä ATS Score: {ats_score}%\"\n",
        "\n",
        "# STEP 6: GPT call\n",
        "def generate_with_gpt(prompt, max_tokens=1500):\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\":\"system\",\"content\":\"You are a resume and cover letter expert.\"},\n",
        "            {\"role\":\"user\",\"content\":prompt}\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    return resp.choices[0].message.content.strip()\n",
        "\n",
        "# STEP 7: Extract job keywords\n",
        "def extract_job_keywords(jd, top_n=25):\n",
        "    vec = CountVectorizer(stop_words='english')\n",
        "    mat = vec.fit_transform([jd])\n",
        "    sums = np.asarray(mat.sum(axis=0)).flatten()\n",
        "    freq = {w:sums[i] for w,i in vec.vocabulary_.items()}\n",
        "    sorted_kws = sorted(freq.items(), key=lambda x:x[1], reverse=True)\n",
        "    return [kw for kw,_ in sorted_kws[:top_n]]\n",
        "\n",
        "extracted_keywords = extract_job_keywords(job_description, top_n=25)\n",
        "formatted_keywords = \", \".join(extracted_keywords)\n",
        "\n",
        "# STEP 8: Prompts\n",
        "resume_prompt = f\"\"\"\n",
        "Generate an ATS-optimized resume for {user_data} based on the following candidate profile and make it humanized and easy to read and understand using HARVARD RESUME STYLES and job description.\n",
        "\n",
        "Requirements:\n",
        "- Format: Plain text (no markdown), styled for Arial 11pt.\n",
        "- Sections (in order):\n",
        "  1. Contact Information\n",
        "  2. Professional Summary (using userdata and job description.)\n",
        "  3. Key Skills (grouped by relevant categories and if there is any skills from the job description show the  in the end of resume as a suggestions to add them.√†)\n",
        "  4. Work Experience (with concise bullet points and metrics)\n",
        "  5. Projects (include your role, technologies used, and outcomes and using the link analyze the project and  ake it look good dfor the resume.)\n",
        "  6. Education ( show all the achievements)\n",
        "  7. Certifications\n",
        "- Add missing keywords and skills which are not in user's resume  (for example; MISSING K&S: skill1, skill2, ...)from the job description at the bottom.\n",
        "- ATS Optimization: Integrate keywords from the job description organically. ‚Äù.\n",
        "\n",
        "\n",
        "USER:\n",
        "{user_data}\n",
        "\n",
        "JOB:\n",
        "{job_description}\n",
        "\"\"\"\n",
        "\n",
        "cover_letter_prompt = f\"\"\"\n",
        "Generate a professional, humanized with no ai detection and easy to read and understand , ATS-friendly cover letter for {user_data} applying to the role described below.\n",
        "\n",
        "Requirements:\n",
        "- Format: Plain text (no markdown), paragraph style.\n",
        "- Sections (in order):\n",
        "  1. Greeting: Address the hiring team or hiring manager by name if known.\n",
        "  2. Introduction: Briefly state the position you‚Äôre applying for and why you‚Äôre excited.\n",
        "  3. Body:\n",
        "     - Alignment of Skills & Experience: Highlight 2‚Äì3 key qualifications from your profile that directly match the job requirements.\n",
        "     - Value Proposition: Explain what you‚Äôll bring to the team (e.g., leadership, technical impact).\n",
        "  4. Closing & Call to Action: Express enthusiasm, reference attached resume, and invite next steps.\n",
        "  5. Signature: ‚ÄúSincerely,‚Äù plus your name.\n",
        "\n",
        "\n",
        "USER:\n",
        "{user_data}\n",
        "\n",
        "JOB:\n",
        "{job_description}\n",
        "\"\"\"\n",
        "\n",
        "# STEP 9: Strict resume optimizer\n",
        "def gpt_strict_keyword_resume(user_data, jd, keywords):\n",
        "    prompt = (\n",
        "        \"Rewrite the resume using the user's data. You MUST include these keywords exactly \"\n",
        "        \"and integrate them naturally into the resume:\\n\\n\"\n",
        "        f\"Keywords: {keywords}\\n\\n\"\n",
        "        \"Use structure:\\n\"\n",
        "        \"1. Contact Info\\n2. Summary\\n3. Skills\\n4. Experience\\n5. Projects\\n6. Education\\n7. Certifications\\n\\n\"\n",
        "        \"Optimize for 90%+ ATS.\\n\\n\"\n",
        "        f\"USER INFO:\\n{user_data}\\n\\nJOB DESCRIPTION:\\n{jd}\"\n",
        "    )\n",
        "    return generate_with_gpt(prompt)\n",
        "\n",
        "# STEP 10: Generate documents & scores\n",
        "resume = generate_with_gpt(resume_prompt)\n",
        "resume_score = calculate_ats_score(resume, job_description)\n",
        "resume_output = attach_ats_score_to_output(resume, resume_score)\n",
        "\n",
        "cover_letter = generate_with_gpt(cover_letter_prompt, max_tokens=600)\n",
        "cover_letter_score = calculate_ats_score(cover_letter, job_description)\n",
        "cover_letter_output = attach_ats_score_to_output(cover_letter, cover_letter_score)\n",
        "\n",
        "strict_resume = gpt_strict_keyword_resume(user_data, job_description, formatted_keywords)\n",
        "strict_resume_score = calculate_ats_score(strict_resume, job_description)\n",
        "strict_resume_output = attach_ats_score_to_output(strict_resume, strict_resume_score)\n",
        "\n",
        "# STEP 11: Normalize resume text for matching\n",
        "resume_norm = re.sub(r\"[^\\w\\s]\", \" \", strict_resume.lower())\n",
        "resume_tokens = set(resume_norm.split())\n",
        "\n",
        "# STEP 12: Identify missing keywords\n",
        "missing_keywords = [kw for kw in extracted_keywords if kw.lower() not in resume_tokens]\n",
        "\n",
        "# STEP 13: Emails\n",
        "# %%\n",
        "import re\n",
        "\n",
        "# 13a) Extract ‚ÄúRole‚Äù and ‚ÄúCompany‚Äù from your job_description string\n",
        "m = re.search(r'([A-Z][A-Za-z0-9 &\\+\\-]+?) at ([A-Z][A-Za-z0-9 &\\+\\-]+)', job_description)\n",
        "if m:\n",
        "    role    = m.group(1).strip()\n",
        "    company = m.group(2).strip()\n",
        "else:\n",
        "    role    = \"the position\"\n",
        "    company = \"the company\"\n",
        "\n",
        "print(f\"üîç Detected Role: {role}  |  Company: {company}\")\n",
        "\n",
        "# 13b) Build & call GPT for the initial application email\n",
        "app_prompt = f\"\"\"\n",
        "Create a warm, professional initial email to the hiring team at {company} for the {role} role.\n",
        "\n",
        "Requirements:\n",
        "1. Greeting (e.g. ‚ÄúDear Hiring Team,‚Äù).\n",
        "2. One line stating the role and your excitement.\n",
        "3. 2‚Äì3 sentences tying your top skills/experiences to key requirements in the job description.\n",
        "4. Closing that references your attached resume and cover letter and invites next steps.\n",
        "5. Sign-off (‚ÄúSincerely,‚Äù or ‚ÄúBest regards,‚Äù) + your name.\n",
        "\n",
        "PROFILE:\n",
        "{user_data}\n",
        "\n",
        "JOB DESCRIPTION:\n",
        "{job_description}\n",
        "\"\"\"\n",
        "\n",
        "application_email = generate_with_gpt(app_prompt, max_tokens=300)\n",
        "\n",
        "# 13c) Build & call GPT for the follow-up email\n",
        "followup_prompt = f\"\"\"\n",
        "Write a concise, polite follow-up email regarding your application for the {role} role at {company}.\n",
        "\n",
        "Requirements:\n",
        "1. Subject line: ‚ÄúFollow-Up: {role} Application‚Äù.\n",
        "2. Pleasant greeting.\n",
        "3. One sentence reminding them of your application.\n",
        "4. One sentence reaffirming your enthusiasm and fit.\n",
        "5. Call to action (‚ÄúI‚Äôd welcome the chance to discuss further.‚Äù).\n",
        "6. Sign-off and your name.\n",
        "\n",
        "PROFILE:\n",
        "{user_data}\n",
        "\n",
        "JOB DESCRIPTION:\n",
        "{job_description}\n",
        "\"\"\"\n",
        "\n",
        "follow_up_email = generate_with_gpt(followup_prompt, max_tokens=300)\n",
        "\n",
        "# STEP 14: Display outputs\n",
        "print(\"üìÑ ORIGINAL RESUME:\\n\\n\", resume_output)\n",
        "print(\"\\nüìÑ OPTIMIZED RESUME (ENFORCED KEYWORDS):\\n\\n\", strict_resume_output)\n",
        "print(\"\\nüì© COVER LETTER:\\n\\n\", cover_letter_output)\n",
        "print(\"\\nüìß APPLICATION EMAIL:\\n\\n\", application_email)\n",
        "print(\"\\nüîÅ FOLLOW-UP EMAIL:\\n\\n\", follow_up_email)\n",
        "print(f\"\\nüîç ATS Score BEFORE: {resume_score}% | AFTER: {strict_resume_score}% ‚úÖ\")\n",
        "\n",
        "# STEP 15: Suggest missing skills\n",
        "if strict_resume_score < 90:\n",
        "    print(\"\\n‚ö†Ô∏è To reach 90%+ ATS, consider adding these keywords:\")\n",
        "    print(\", \".join(missing_keywords))\n",
        "else:\n",
        "    print(\"\\n‚úÖ Your resume meets the 90%+ ATS threshold!\")"
      ],
      "metadata": {
        "id": "e39YA7z0zajR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        },
        "outputId": "f67a90b6-d391-4667-b037-e9787d0ad69b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.0)\n",
            "Collecting openai\n",
            "  Downloading openai-1.78.1-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Downloading openai-1.78.1-py3-none-any.whl (680 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m680.9/680.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.78.0\n",
            "    Uninstalling openai-1.78.0:\n",
            "      Successfully uninstalled openai-1.78.0\n",
            "Successfully installed openai-1.78.1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: YOUR CHA******** KEY. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5fa269b483a2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;31m# STEP 10: Generate documents & scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_with_gpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0mresume_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_ats_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0mresume_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_ats_score_to_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-5fa269b483a2>\u001b[0m in \u001b[0;36mgenerate_with_gpt\u001b[0;34m(prompt, max_tokens)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# STEP 6: GPT call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_with_gpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     resp = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    923\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    924\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    926\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         )\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: YOUR CHA******** KEY. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
          ]
        }
      ]
    }
  ]
}